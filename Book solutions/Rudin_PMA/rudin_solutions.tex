% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------

\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb,scrextend}
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage{xcolor}
\usepackage{enumitem}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\renewcommand{\qed}{\hfill$\blacksquare$}
\let\newproof\proof
\renewenvironment{proof}{\begin{addmargin}[1em]{0em}\begin{newproof}}{\end{newproof}\end{addmargin}\qed}
% \newcommand{\expl}[1]{\text{\hfill[#1]}$}

\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{reflection}[2][Reflection]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{proposition}[2][Proposition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}



\begin{document}

% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------

\lhead{Rudin \textit{PMA} Solutions}
\chead{Stan Tuznik}
\rhead{\today}

% \maketitle
\section*{Chapter 1. The Real and Complex Number Systems}

\begin{problem}{1.1}
If $r$ is rational ($r\neq0$) and $x$ is irrational, prove that $r+x$ and $rx$ are irrational.
\end{problem}
\begin{proof}
The easiest way to show this is to recall that $\mathbb{Q}$ is closed under addition and scalar multiplication. Thus, assume by way of contradiction that $r+x\in \mathbb{Q}$. Then certainly $$ \left(r+x\right)-r = x \in \mathbb{Q}$$ but this contradicts our assumptions. Similarly, if $rx\in\mathbb{Q}$, then $$ \left(rx\right) \cdot \frac{1}{r} = x \in \mathbb{Q}$$ and we are done.
\end{proof}


\begin{problem}{1.2}
Prove that there is no rational number whose square is 12.
\end{problem}
\begin{proof}
Assume $q = \frac{m}{n} \in\mathbb{Q}$ for $m,n \in \mathbb{Z}, n \neq 0,$ is a rational number in lowest terms, i.e., $m$ and $n$ have no common terms, and that we have $q^2 = 12$. Then we have $m^2 = 12 n^2 = 2 \cdot 6n^2$. Hence, $m$ must be even, i.e., $m=2k$ for some $k\in \mathbb{Z}$. But then $k^2 = 3n^2$. Since $n$ cannot be even (otherwise $n$ and $m$ would have a factor of $2$ in common), we must have $n$ odd. Then $k$ must be odd since it is a product of odd numbers ($3n^2$). That is, $$ k =2y+1 \; \text{and} \; n = 2z+1$$ for some $y,z\in\mathbb{Z}$. Plugging these into the equation, we get $$ 4y^2 + 4y + 1 = 3\left(4z^2 + 4z + 1\right) $$ which, upon rearranging terms, is $$ 4\left(y^2 + y -3z^2 - 3z\right) = 2 $$ Notice that the quantity in parenthesis is an integer (thanks to the closure of the integers under addition and multiplication), call it $r$. Then we have $$ 4r = 2$$ which is certainly not satisfied for any integer. Hence, $\sqrt{12}\notin \mathbb{Q}$.
\end{proof}

Below is an alternate proof whose trick was suggested to me online.\\

\begin{proof}
We can write $\sqrt{12} = 2\sqrt{3}$ and the previous exercise indicates that rational multiples of irrationals are still irrational; thus, we can instead show that $\sqrt{3}$ is irrational. Proceed in the usual way: assume $m,n\in \mathbb{Z}, n\neq 0,$ in lowest terms with $\frac{m^2}{n^2} = 3$ so that $m^2 = 3 n^2$.
\end{proof}





\begin{problem}{1.3}
Prove Proposition 1.15.
\end{problem}
\begin{proof} 
These are relatively straightforward consequences of the multiplication axioms for fields
\begin{enumerate}[label=(\alph*)]
	\item Assume $x\neq 0$ and $xy=xz$. Then \begin{align*}
	y & = 1 y \\
	& = \left(x^{-1}x\right)y \\
	& = x^{-1}\left(xy\right) \\
	& = x^{-1}\left(xz\right) \\
	& = \left(x^{-1}x\right)z \\
	& = 1 z \\
	& = z
	\end{align*}
	\item Assume $x\neq 0$ and $xy=x$. Then  \begin{align*}
	y & = 1 y \\
	& = \left(x^{-1}x\right)y \\
	& = x^{-1}\left(xy\right) \\
	& = x^{-1}\left(x\right) \\
	& = x^{-1}x \\
	& = 1
	\end{align*}
	\item Assume $x\neq 0 $ and $xy=1$. Then \begin{align*}
	y & = 1 y \\
	& = \left(x^{-1}x\right)y \\
	& = x^{-1}\left(xy\right) \\
	& = x^{-1}\left(1\right) \\
	& = x^{-1} 
	\end{align*}
	\item Assume $x\neq 0$. Then \begin{align*}
	\left(x^{-1}\right)^{-1} & = 1\left(x^{-1}\right)^{-1} \\
	& = \left(x x^{-1}\right)\left(x^{-1}\right)^{-1} \\
	& = x \left(x^{-1} \left(x^{-1}\right)^{-1} \right) \\
	& = x \left(1\right) \\ 
	& = x
	\end{align*}
\end{enumerate}
\end{proof}






\begin{problem}{1.4}
Let $E$ be a nonempty subset of an ordered set; suppose $\alpha$ is a lower bound of $E$ and $\beta$ is an upper bound of $E$. Prove that $\alpha \leq \beta$.
\end{problem}
\begin{proof}
This seems almost obvious, yet is a careful consequence of the order axioms. Since $E \neq \varphi$, there is some $x \in E$. Then since $E$ is a subset of an ordered set, and by definition of bounds, we have $$ \alpha \leq x \leq \beta. $$ From the transitivity of orders, we have $\alpha \leq \beta$.
\end{proof}

\begin{problem}{1.5}
Let $A$ be a nonempty set of real numbers which is bounded below. Let $- A$ be the set of all numbers $-x$, where $x\in A$. Prove that $$ \inf A = -\sup \left(-A\right) $$
\end{problem}
\begin{proof}
Again, this is a seemingly straightforward conclusion that requires some axiomatic precision.

First, we show that the relevant bounds exist. If $A$ is bounded below, then by the completeness axiom, it has a greatest lower bound, $\beta = \inf A$. That is, for any $x\in A$ (guaranteed at least one, since $A\neq \varphi$), we have $$ \beta \leq x. $$ By properties of $\mathbb{R}$ as an ordered field, we have, equivalently, $$ -x \leq -\beta. $$ Notice that $$ x\in A \iff -x \in -A $$ so that $-\beta$ is an upper bound on the set $-A$. By completeness of $\mathbb{R}$, again, $-A$ has some least upper bound, written $\alpha = \sup -A$.

The goal now is to show that $\beta = -\alpha$. Let $b$ be an arbitrary lower bound of $A$. Then $-b$ is an upper bound of $-A$, as shown above. Hence, $-b \geq \sup -A$ by definition of supremum. But then $b \leq -\sup -A$ by properties of the ordering on $\mathbb{R}$, and so we have any lower bound of $A$ below $-\alpha$. If we can show that $-\alpha$ is indeed a lower bound on $A$, then we are done. Assume by way of contradiction that there is some $x\in A$ with $x < -\alpha$. Then we have $\alpha < -x$ and $-x \in -A$. This contradicts the definition of $\alpha = \sup -A$, and so no such $x\in A$ may exists. Hence, $-\alpha$ is a lower bound on $A$ which is greater than all other lower bounds; we have proven $$ \inf A = -\sup -A $$
\end{proof}



\begin{problem}{1.6} 
Fix $b>1$.
\begin{enumerate}[label=(\alph*)]
	\item hi
\end{enumerate}
\end{problem}




\begin{problem}{1.11}
If $z$ is a complex number, prove that there exists an $r\geq 0$ and a complex number $w$ with $\left|w\right|=1$ such that $z=rw$. Are $w$ and $r$ always uniquely determined by $z$?
\end{problem} 
\begin{proof}
This can be accomplished by cleverly decomposing $z$: $$ z= \left|z\right| \frac{z}{\left|z\right|} = rw $$ where $r=\left|z\right|$ and $w = z / \left|z\right|$. Certainly $\left|w\right|=1$.

We can easily prove the uniqueness. Assume we have two decompositions which satisfy the hypotheses: $$ z= rw = r'w'. $$ Then by taking the magnitude of both, we have $$  r = \left|r\right| = \left|r\right|\left|w\right| = \left|rw\right| = \left|r'w'\right| = \left|r'\right| \left| w'\right| = \left|r'\right| = r' $$ Since $r= r'$, we have $$ rw = r'w' \implies w=w' $$ completing the proof.
\end{proof}


\begin{problem}{1.12}
If $z_1,\ldots,z_n$ are complex, prove that $$ \left|z_1 + z_2 + \cdots + z_n \right| \leq \left|z_1\right| + \left|z_2\right| + \cdots + \left|z_n\right|. $$
\end{problem}
\begin{proof}
This is a straightforward induction proof. The base case where $n=2$ clearly holds by the triangle inequality for complex absolute value (Rudin, Theorem 1.33). Assume the conclusion holds for some $n\in \mathbb{N}$. Then consider some set $\left\{z_1,z_2,\ldots,z_{n+1}\right\}$ of complex numbers. Then \begin{align*}
\left|z_1 + z_2 + \cdots + z_n + z_{n+1}\right| & = \left|\left(z_1 + z_2 + \cdots + z_n\right) + z_{n+1}\right| \\ & \leq \left| z_1 + z_2 + \cdots + z_n\right| + \left| z_{n+1}\right| \\
& \leq \left|z_1\right| + \left|z_2\right| + \cdots + \left|z_n\right| + \left|z_{n+1}\right| 
\end{align*} where the base case was used in the second step and the induction hypothesis was used in the third step. This completes the proof.
\end{proof}



\begin{problem}{1.13}
If $x$, $y$ are complex, prove that $$ \left| \left|x\right| - \left|y\right| \right| \leq \left|x-y\right|. $$
\end{problem}
\begin{proof}
This is an easy corollary of the triangle inequality. Let $x,y \in \mathbb{C}$. Then \begin{align*}
\left| x\right| & = \left| \left(x-y\right) + y\right| \\ & \leq \left|x-y\right| + \left|y\right| 
\end{align*}
so that $\left|x\right| - \left|y\right| \leq \left|x-y\right|$. We can repeat this starting with $\left|y\right|$ to obtain $\left|y\right| - \left|x\right| \leq \left|x-y\right|$ as well. Thus, taken together, we have the conclusion proven.
\end{proof}


\begin{problem}{1.14}
If $z$ is a complex number such that $\left|z\right|=1$, that is, such that $z\overline{z}=1$, compute $$ \left|1+z\right|^2 + \left|1-z\right|^2.$$
\end{problem}
\begin{proof}
We can compute this by appealing to the definition of the absolute value of complex numbers: \begin{align*}
\left|1+z\right|^2 + \left|1-z\right|^2 & = \left(1+z\right)\left(1+\overline{z}\right) + \left(1-z\right)\left(1-\overline{z}\right) \\ & = 1+z+\overline{z} + \left|z\right|^2 + 1 -z -\overline{z} + \left|z\right|^2 \\ & = 2 + 2\left|z\right|^2 \\ & = 4
\end{align*}
\end{proof}


\begin{problem}{1.15}
Under what conditions does equality hold in the Schwarz inequality?
\end{problem}
\begin{proof}
We must look to the proof.

Equality obviously holds if one or both of the vectors are zero. If not, the inequality is introduced in the proof by showing that $ \sum_j \left|Ba_j- Cb_j\right|^2 \geq 0.$ Equality will hold if $$ B a_j - Cb_j = 0, $$ that is, if we have $a_j \propto b_j$ for each $j$. In other words, the vectors $a$ and $b$ must be linearly dependent. Conversely, if the vectors are linearly dependent, it is easy to see that equality holds.
\end{proof}




\begin{problem}{1.17}
Prove that $$ \left|x+y\right|^2 + \left|x-y\right|^2 = 2\left|x\right|^2 + 2\left|y\right|^2 $$ if $x\in \mathbb{R}^k$ and $y\in \mathbb{R}^k$. Interpret this geometrically, as a statement about parallelograms.
\end{problem}
\begin{proof}
This identity is straightforward to prove by proceeding left-to-right: \begin{align*}
\left|x+y\right|^2 + \left|x-y\right|^2 & = x^2 + y^2 +2xy + x^2 + y^2 -2xy \\ & = 2x^2 + 2y^2 \\ & = \left|x\right|^2 + \left|y\right|^2 
\end{align*}
Thinking of $x$ and $y$ as plane vectors, centered at the origin, $\left|x\right|^2+\left|y\right\|^2$ is the sum of squares of the lengths of two neighboring sides of a parallelogram, while $\left|x+y\right|^2 + \left|x-y\right|^2$ is the sum of squares of the lengths of the face diagonals of the same parallelogram. This proof shows that the two quantities are equal.
\end{proof}

\begin{problem}{1.18}
If $k\geq 2$ and $x\in \mathbb{R}^k$, prove that there exists $y\in \mathbb{R}^k$ such that $y\neq 0$ but $x\cdot y = 0$. Is this also true if $k=1$?
\end{problem}
\begin{proof}
First, this is not true in $\mathbb{R}^1$, in general. Assume by way of contradiction that for some $x\in \mathbb{R}^k$, there is some $y\in \mathbb{R}^k$ with $y \neq 0$ but $x\cdot y = 0$. Then since $y\neq 0$, we have $x=xy y^{-1}=0\cdot y^{-1} = 0$. The converse with $x=0$ is easy to show. Thus, this only holds for $x=0$ in $\mathbb{R}^1$.

In $\mathbb{R}^k$, the conclusion holds if $x=0$ easily, so assume $x\neq 0$. That is, $x$ has some component, $x_j$, $j\in \left\{1,2,\ldots,k\right\}$, which is nonzero. Then we can construct the desired $y$ with components $y_i = 1$ for $i\neq j$ and $y_j = -\frac{\sum_{k\neq j} x_ky_k}{x_j}$. Compute the dot product to see that $x\cdot y =0 $, and $y$ is certainly nonzero (since it has all the $1$'s).
\end{proof}





\begin{problem}{1.19}
Suppose $a\in \mathbb{R}^k$, $b\in \mathbb{R}^k$. Find $c\in \mathbb{R}^k$ and $r>0$ such that $$ \left|x-a\right| = 2\left|x-b\right| $$ if and only if $\left|x-c\right| = r$.
\end{problem}
\begin{proof}

\end{proof}











\newpage
\section*{Chapter 2. Basic Topology}

\begin{problem}{2.1}
Prove that the empty set is a subset of every set.
\end{problem}
\begin{proof}
The empty set $\varnothing$ is a subset of another set $E$ if $x \in \varnothing\implies x \in E$. Since $\varnothing$ contains no elements, the statement is vacuously true (the antecedent can never be satisfied).
\end{proof}



\begin{problem}{2.2}
A complex number $z$ is said to be \textit{algebraic} if there are integers $a_0,\ldots,a_n$, not all zero, such that $$ a_0 z^n + a_1 z^{n-1} + \cdots + a_{n-1} z + a_n = 0.$$ Prove that the set of all algebraic numbers is countable. \textit{Hint}: For every positive integer $N$ there are only finitely many equations with $$ n + \left|a_0\right| + \left|a_1\right| + \cdots + \left|a_n\right| = N.$$
\end{problem}



\begin{problem}{2.3}
Prove that there exist real numbers which are not algebraic.
\end{problem}
\begin{proof}
From problem 2.2 we know that the set of algebraic numbers are countable. If all real numbers were algebraic, then the real numbers would be countable. However, we know that this is not the case. Hence, there must be non-algebraic real numbers.
\end{proof}










\begin{problem}{2.4}
Is the set of all irrational real numbers countable?
\end{problem}
\begin{proof}
Assume that the irrational numbers are countable. We know that the real numbers are uncountable (think: the diagonalization argument involving decimals), that the rational numbers are countable, and that the real numbers are the union of the rational and irrational numbers. Then the real numbers are the union of two countable sets, which is itself countable (this is a simple lemma to prove). Thus, we have the real numbers both countable and uncountable, which is a contradiction.
\end{proof}


\begin{problem}{2.5}
Construct a bounded set of real numbers with exactly three limit points.
\end{problem}
\begin{proof}
An easy way to construct this set would be to make a sequence which alternatingly approaches three separate limit points. For example, let $\left(a_n\right)$ be the sequence $$ 1,2,3,1,2,3,1,2,3,\ldots $$ and let $\left(b_n\right)$ be the sequence $$ b_n = a_n + \frac{1}{n+1}. $$ Then the set $\left\{b_n\right\}_{n=1}^{\infty}$ is bounded and has $1$, $2$, and $3$ as limit points.

Another example, which I was suggested by a friend, cleverly uses the sine function to write $$ a_n = \sin \left(\frac{2\pi}{3} n\right) + \frac{1}{n}. $$
\end{proof}









\begin{problem}{2.6}
Let $E'$ be the set of all limit points of a set $E$. Prove that $E'$ is closed. Prove that $E$ and $\overline{E}$ have the same limit points. (Recall that $\overline{E}=E\cup E'$.) Do $E$ and $E'$ always have the same limit points?
\end{problem}
\begin{proof}
Let $x$ be a limit point of $E'$. We want to show that $x \in E'$. Since $x$ is a limit point, for any neighborhood $N$ of $x$, we have some point $y \in N\cap E'$. That is, $y$ is a limit point of $E$. Then since $N$ is a neighborhood of $y$, there is some point $z \in N\cap E$. But then for any arbitrary neighborhood of $x$, $N$, we have found a point $z \in E$ with $z \in N$. Thus, $x$ is a limit point of $E$, i.e., $x\in E'$. That is, $E'$ contains all of its limit points, and is closed by definition.

{\color{red} We can alternatively approach this problem from the equivalent definition of a closed set as a complement of an open set. Let $x\notin E'$. Then $x$ is not a limit point of $E$. That is, there is some neighborhood $N$ of $x$ which does not intersect $E$: $N\cap E = \varnothing$. We claim also that $N\cap E' = \varnothing$. Otherwise, if $z \in N \cap E'$, then since $z \in E'$, and $N$ is a neighborhood of $z$, there is some point $p \in E$ with $p \in N$. But now we have a point $p$ of $E$ in our neighborhood $N$ of $x$, which we constructed to have no such points of $E$. $\bot$ Hence we have $N\cap E' = \varnothing$, and so $N$ is a neighborhood of $x$ which does not intersect $E'$. Thus, $E'$ is closed since $E'^c$ is open.}

Let $x$ be a limit point of $E$. Then let $N$ be a neighborhood of $x$. Then there is a $y\in E$ with $y\in N$. But then $y \in E \subset E\cup E' = \overline{E}$, so arbitrary neighborhoods of $x$ contain points of $\overline{E}$. Thus, $x$ is a limit point of $\overline{E}$. Conversely, let $x$ be a limit point of $\overline{E}$, with $N$ a neighborhood of $x$. Then $x$ contains some point of $\overline{E}$, say $y$. If $y\in E$, then $N$ trivially contains a point $y$ of $E$. Otherwise, if $y \in E'$, then since $N$ is a neighborhood of $y$, $N$ contains some point $z \in E$. Thus, in either case, neighborhood $N$ of $x$ contains a point of $E$; $x$ is a limit point of $E$. From both directions, we see that the limit points of $E$ and of $\overline{E}$ are the same.

Let $E = \left\{ \frac{1}{n} \, | \, n\in \mathbb{N} \right\}$. Then surely $E' = \left\{0\right\}$, which has no limit points. But since $0$ is a limit point of $E$, $E$ and $E'$ do not have the same limit points.
\end{proof}



\begin{problem}{2.7}
Let $A_1$, $A_2$, $A_3$, \ldots be subsets of a metric space.
\begin{enumerate}[label=(\alph*)]
	\item If $B_n = \cup_{i=1}^n A_i$, prove that $\overline{B}_n = \cup_{i=1}^n \overline{A}_i$ for $n=1,2,3,\ldots$.
	\item If $B = \cup_{i=1}^{\infty} A_i$, prove that $\overline{B} \supset \cup_{i=1}^{\infty} \overline{A}_i$.
\end{enumerate}
Show, by an example, that this inclusion can be proper.
\end{problem}

\begin{proof}
\begin{enumerate}[label=(\alph*)]
	\item Let $x \in \overline{B}_n$. Let $x\in \overline{B}_n$. Thus, $x\in A_i$ for some $i$. Then $x \in A_i \subseteq \overline{A}_i \subseteq \cup_{j=1}^n \overline{A}_j $. Conversely, let $x \in \cup_{i=1}^n \overline{A}_i$. Then $x\in \overline{A}_i$ for some $i$. If $x \in A_i$, then $x\in B_n$. If $x \notin A_i$, then $x$ must be a limit point of $A_i$, hence we can construct an arbitrary open ball about $x$ and find some $y\in A_i$ within this ball; but then $y_i \in B_n$ by definition of $B_n$, and so $x$ is a limit point of $B_n$. Hence, taking the cases together, we have $\cup_{i=1}^n \overline{A}_i \subseteq \overline{B}_n$. Since we have proven both directions, the equality holds.
	\item Assume that $B = \cup_{i=1}^{\infty} A_i$, and let $x \in \cup_{i=1}^{\infty} \overline{A}_i$. Then $x \in \overline{A_i}$ for some $i$. If $x \in A_i$, then $x \in B$. Otherwise, $x$ is a limit point of $A_i$. As in part (a), construct a ball neighborhood about $x$ and choose the guaranteed $y\in A_i$ within this neighborhood. Then $y \in B$, and so $x$ is again a limit point of $B$. Thus, $x \in \overline{B}$.
\end{enumerate}


Interesting things happen when we take an infinite union, however. It is possible to have a countable union of closures which are a proper subset of the closure of the union. How? 

Let $A_i = \left(\frac{1}{n},1\right)$. Then note that $B=\cup_{i=1}^{\infty} A_i = \left(0,1\right)$ and that $\overline{A_i} = \left[\frac{1}{n},1\right]$. However, $\cup_{i=1}^{\infty} \overline{A_i} = \left(0,1\right]$; $0$ is not included since if it were, this implies that $0\in \left[\frac{1}{n},1\right]$ for some $n\in \mathbb{N}$, which is certainly not true. However, $\overline{B} = \left[0,1\right]$, and so the union of the closures is contained within the closure of the unions.
\end{proof}




\begin{problem}{2.8}
Is every point of every open set $E \subset \mathbb{R}^2$ a limit point of $E$? Answer the same question for closed sets in $\mathbb{R}^2$.
\end{problem}
\begin{proof}
Every point of an open set in $E\subset \mathbb{R}^2$ is a limit point of $E$. Let $x\in E$. Then since $E$ open, there is an open ball neighborhood (i.e., a basis element) about $x$, say $B_r\left(x\right)$, so that $x\in B_r\left(x\right) \subset E$ for some radius $r>0$. Then we have some $y\neq x$ in $B_r\left(x\right) \subset E$, so we have $x$ a limit point of $E$. {\color{red}Note that the metric space is what allows us to provide the balls. These may not exist in a general space. For example, in the discrete topology, no points are limit points!}

This is certainly not true for closed sets. For example, the set $\left\{\left(1,2\right)\right\}\subset \mathbb{R}^2$ is closed but contains no limit points.
\end{proof}









\begin{problem}{2.9}
Let $E^{\circ}$ denote the set of all interior points of a set $E$. [$E^{\circ}$ is called the interior of $E$.]
\begin{enumerate}[label=(\alph*)]
	\item Prove that $E^{\circ}$ is always open.
	\item Prove that $E$ is open if and only if $E^{\circ} = E$.
	\item If $G\subset E$ and $G$ is open, prove that $G\subset E^{\circ}$.
	\item Prove that the complement of $E^{\circ}$ is the closure of the complement of $E$.
	\item Do $E$ and $\overline{E}$ always have the same interiors?
	\item Do $E$ and $E^{\circ}$ always have the same closures?
\end{enumerate}
\end{problem}
\begin{proof}
\begin{enumerate}[label=(\alph*)]
	\item We must show that every point of $E^{\circ}$ is an interior point (to $E^{\circ}$). Let $x\in E^{\circ}$. Then there is some neighborhood $N$ of $x$ with $N\subset E$. We want to show that this neighborhood $N$ is contained within $E^{\circ}$ as well. Consider any other $y\in N$; then $y$ is contained in a neighborhood --- namely, $N$ --- which is contained within $E$. Hence, $y$ is also an interior point of $E$. Since this logic holds for any other $y\in N$, we have $N \subseteq E^{\circ}$, and so $E^{\circ}$ is open.
	
	\item Assume $E$ is open. Then every point of $E$ is interior to $E$, so $E \subseteq E^{\circ}$. On the other hand, $E^{\circ} \subseteq E$ by definition, so $E=E^{\circ}$. Conversely, assume that $E=E^{\circ}$. Then every point of $E$ is also interior to $E$, i.e., $E$ is open by definition.
	
	\item Let $G\subset E$, $G$ open. Let $x \in G$. Then, since $G$ is open, there is some neighborhood of $x$, say $N$, with $x\in N \subset G \subset E$. Hence, every point of $G$ is an interior point of $E$, so $G\subset E^{\circ}$.
	
	\item We want to show that $\left(E^{\circ}\right)^c = \overline{E^c}$. Let $x \in \left(E^{\circ}\right)^c$, that is, $x\notin E^{\circ}$. Hence, either $x$ is not in $E$ or it is a boundary point of $E$. If $x$ is not in $E$, then $x\in E^c \subseteq \overline{E^c}$. Otherwise, if $x$ is a boundary point of $E$, then every neighborhood of $x$ contains some point $y \in E^c$. That is, $x \in \overline{E^c}$. Taken together, we have shown that $\left(E^{\circ}\right)^c \subseteq \overline{E^c}$. 
	Conversely, assume $x\in \overline{E^c}$. Then every neighborhood of $x$ also contains some point of $E^c$; thus, $x$ cannot be interior to $E$. In other words, $x\in \left(E^{\circ}\right)^{c}$. Thus, $\overline{E^c} \subseteq \left(E^{\circ}\right)^{c}$. 
	We have shown both directions of the equality.
	
	\item $E$ and $\overline{E}$ do not have the same interiors. For example, consider $E = \left(-1,0\right)\cup\left(0,1\right)$ as a subset of $\mathbb{R}$. Then $0$ is not interior to $E$ (it's not even in $E$) but it is interior to $\overline{E}=\left[-1,1\right]$.
	
	\item 
	
\end{enumerate}
\end{proof}







\begin{problem}{2.10}
Let $X$ be an infinite set. For $p\in X$ and $q\in X$, define
\begin{equation*}
 d\left(p,q\right) = \left\{ \begin{array}{lr} 1 & \left(\text{if}\, p\neq q\right) \\ 0 & \left(\text{if}\, p=q\right) \end{array} \right.
\end{equation*}
Prove that this is a metric. Which subsets of the resulting metric space are open? Which are closed? Which are compact?
\end{problem}

\begin{proof}
In order for this to be a metric, it must be non-negative and $d\left(p,q\right) = 0$ only when $p=q$. This is obviously true from the definition of $d$. It is also very clearly symmetric. The final condition is that the triangle inequality must hold for every combination of points $x,y,z \in X$. First, if $x=z$, then $d\left(x,z\right) =0 \leq d\left(x,y\right) + d\left(y,z\right)$ since the right hand side is at least $0$. On the other hand, if $x\neq z$, then $d\left(x,z\right)=1$. If $y\in X$ is such that $y\neq x$ and $y\neq z$, then $d\left(x,y\right) + d\left(y,z\right) = 2$, so the inequality holds. Instead, if $y\neq x$ but $y=z$, then $d\left(x,y\right) + d\left(y,z\right) = 1$ and the inequality holds; this same logic applies if $y\neq x$ but $y=z$. We cannot have both $y=x$ and $y=z$, since we assumed $x\neq z$. Thus in all cases we have the triangle inequality satisfied. This completes the proof that $d$ is a metric. {\color{red}It is the simplest metric, the discrete metric on $X$.}

Recall that Rudin defines $A\subset X$ in metric space $X$ to be open if every point is surrounded by an open ball neighborhood. What do these balls look like in this space? They are $$ B_r\left(x\right) = \left\{ y \in X \, : \, d\left(x,y\right)<r \right\} $$ Keep in mind that we have $d\left(x,y\right) \in \left\{0,1\right\}$ for all $x,y\in X$. If $r<1$, we have 
\begin{align*}
B_r\left(x\right) & = \left\{ y\in X \, : \, d\left(x,y\right) < r \right\} \\
& = \left\{ y \in X \, : \, d\left(x,y\right) = 0\right\} \\
& = \left\{ y\in X \, : \, x=y\right\} \\
& = \left\{ x \right\}
\end{align*}
Thus, some of the balls are the singleton sets. On the other hand, if $r>1$, we can show that $$ B_r\left(x\right) = X,$$ i.e., the whole metric space. Given any subset $A\subset X$, and any $x\in A$, we have $x \in \left\{x\right\} \subset A$, so $A$ is open. That is, all sets are open.

For set $K \subset X$, we have the open cover $\left\{ \left\{k\right\}\, | \, k \in K\right\}$ since the singleton sets are open. This open cover clearly has {\color{red}no subcover}, since removing any one of the singletons would remove the corresponding point from $K$. Thus, an open cover of $K$ has a finite open subcover if and only if this cover itself is the finite open subcover, i.e., if $K$ is a finite set. Thus, the finite subsets of $K$ are the only compact sets in this metric. {\color{red}Note that this example of the discrete metric space really emphasizes compactness as ``the topologist's notion of finiteness.''}
\end{proof}



\begin{problem}{2.11}
For $x\in \mathbb{R}^1$ and $y\in \mathbb{R}^1$, define \begin{align*}
d_1\left(x,y\right) & = \left(x-y\right)^2, \\
d_2\left(x,y\right) & = \sqrt{\left|x-y\right|}, \\
d_3\left(x,y\right) & = \left|x^2-y^2\right|, \\
d_4\left(x,y\right) & = \left|x-2y\right|,\\
d_5\left(x,y\right) & = \frac{\left|x-y\right|}{1+\left|x-y\right|}.
\end{align*} Determine, for each of these, whether it is a metric or not.
\end{problem}
\begin{proof}
\begin{enumerate}
	\item The function $d_1$ is certainly non-negative and zero only when $x=y$; it is also obviously symmetric; it satisfies the triangle inequality. Thus, $d_1$ is a metric.
	\item 
	\item The function $d_3$ is not a metric since it does not satisfy the condition about $d=0$ (called the identity of indiscernibles): note that $d\left(1,-1\right)=0$ but $ 1 \neq -1$.
	\item The function $d_4$ clearly does not satisfy symmetry, so it is not a metric.
	\item 
\end{enumerate}
\end{proof}











\begin{problem}{2.12}
Let $K\subset \mathbb{R}^1$ consist of $0$ and the numbers $1/n$, for $n=1,2,3,\ldots $. Prove that $K$ is compact directly from the definition (without using the Heine-Borel theorem).
\end{problem}
\begin{proof}
{\color{red}The Heine-Borel theorem applies here since $K$ is certainly closed and bounded. Since we cannot use this, we must take an arbitrary open cover of $K$ and construct a finite open subcover. By drawing some pictures, we note that $0$ is a limit point of $K$, and so any open neighborhood $N$ about $0$ must naturally contain some point $1/m$ to the right of it. Then we can use this open set $N$ to cover the infinitely many points ``to the left of'' $1/m$. } Let $\left\{U_{\alpha}\right\}_{\alpha =1}^{\infty}$ be an open cover of $K$. Then $0\in U_{\beta}=:V $ for one of these open sets, which we will call $V$. Then since $0$ is a limit point of $K$ {\color{red}(easy to show)}, we have some point $1/m \in K$ also in $V$. Since we are considering the metric space $\mathbb{R}^1$, we have $1/m' \in V$ for all $ m' $ such that $m' \geq m$. For each $1/n \in K$ with $1\leq n < m$, we have some element of the open cover, say $U_{\gamma}=:V_n$ with $1/n \in V_n$. Then $\cup_{i=1}^{m-1} V_n \cup V $ is a finite open subcover of $K$. Thus, $K$ is compact.
\end{proof}



\begin{problem}{2.13}
Construct a compact set of real numbers whose limit points form a countable set.
\end{problem}
\begin{proof}
{\color{red}I expect that a solution will include the rational numbers or the integers, since these are often used as prototypical countable sets.}
\end{proof}




\begin{problem}{2.14}
Give an example of an open cover of the segment $\left(0,1\right)$ which has no finite subcover.
\end{problem}
\begin{proof}
Let $$U=\left\{ \left(0,\frac{n}{1+n}\right) \, : \, n\in \mathbb{N} \right\}. $$ This is certainly an open cover of $\left(0,1\right)$, since for any $x\in\left(0,1\right)$ we can find an $n \in \mathbb{N}$ so that $x \in \left(0, \frac{n}{1+n}\right) \subset \left(0,1\right)$. Plus, each of these sets is open as an open interval. However, no finite subcover will cover $\left(0,1\right)$, since any finite subcover $V$ of $U$ contains a ``maximal'' covering set: let $$ m = \max \left\{ m\, : \, \left(0,\frac{m}{1+m}\right)\in V \right\}. $$ Then let $m' = \frac{\left(m+1\right)}{1+\left(m+1\right)}$ is in $\left(0,1\right)$ but not in any of the covering sets in $V$. Hence, no finite subset of $U$ truly covers $\left(0,1\right)$.

We have proven that $\left(0,1\right)\subset \mathbb{R}^1$ is not compact.
\end{proof}


\begin{problem}{2.15}
Show that Theorem 2.36 and its Corollary become false (in $\mathbb{R}^1$, for example) if the word ``compact'' is replaced by ``closed'' or by ``bounded.''
\end{problem}
{\color{red}Theorem 2.36 states that given a collection $K$ of compact subsets of a metric space, arbitrary finite intersections of the elements of which are nonempty, we have a nonempty intersection of all elements of $K$. The corollary applies this to a countable sequence of ``decreasing'' sets. This problem aims to show that closedness and boundedness, by themselves, are not enough to make the same conclusion.}
\begin{proof}
The hint suggests that we consider $\mathbb{R}^1$. We first consider a collection of closed subsets; note that we need them to be unbounded, otherwise they will be compact and Theorem 2.36 would apply. Let $$ K = \left\{ \left[n, \infty\right) \, : \, n\in \mathbb{N}\right\}. $$ Then each set is closed, and arbitrary finite intersections of these sets are nonempty. However, the intersection is certainly empty: if $x \in \cap_{n\in \mathbb{N}} \left[n,\infty\right)$, then $x \in \left[n,\infty\right)$ for all $n\in \mathbb{N}$. Hence, $x\geq n$ for all $n$. This is clearly impossible, since we can always find some (infinitely many) natural numbers greater than any arbitrary real number. Thus, we can have no $x$ in this intersection, and so it is empty. Note that this is also a counterexample for the corollary, since the subsets are decreasing.

In the second case, we must look at bounded by non-closed subsets of $\mathbb{R}^1$. The counterexample we provide here is similar to the previous one: $$K = \left\{ \left[\frac{n}{n+1},1\right) \, : \, n\in \mathbb{N}\right\}.$$ Each of these is not closed, since $1$ is a limit point of each and is contained in none, but the intersection is empty, for reasons similar to the previous case. Again, it is also a counterexample to the corollary since the sets are decreasing.
\end{proof}







\begin{problem}{2.16}
Regard $\mathbb{Q}$, the set of all rational numbers, as a metric space, with $d\left(p,q\right)=\left|p-q\right|$. Let $E$ be the set of all $p\in \mathbb{Q}$ such that $2 < p^2 < 3$. Show that $E$ is closed and bounded in $\mathbb{Q}$, but that $E$ is not compact. Is $E$ open in $\mathbb{Q}$?
\end{problem}
\begin{proof}
Let $\mathbb{Q}$ be the metric space described in the problem statement, and let $E = \left\{p\in \mathbb{Q}\,|\, 2<p^2<3\right\}$. Certainly $2$ and $-2$ are upper and lower bounds for $E$, respectively, since $2^2 =4 > 3$; hence, $E$ is bounded. 

Let $x \notin E$. Then $x\in \mathbb{Q}$ but either $x^2 \leq 2$ or $x^3 \geq 3$. Consider first the case in which $x^2 \leq 2$. Certainly, then, $x^2<2 $ since $x^2=2$ for no rational $x$. 

\end{proof}






\begin{problem}{2.17}
Let $E$ be the set of all $x\in\left[0,1\right]$ whose decimal expansion contains only the digits $4$ and $7$. Is $E$ countable? Is $E$ dense in $\left[0,1\right]$? is $E$ compact? Is $E$ perfect?
\end{problem}


\begin{problem}{2.18}
Is there a nonempty perfect set in $\mathbb{R}^1$ which contains no rational number?
\end{problem}
\begin{proof}
{\color{red}Recall that a perfect set is one which is closed and in which every point is a limit point.} 
\end{proof}




\begin{problem}{2.19}
\begin{enumerate}[label=(\alph*)]
	\item If $A$ and $B$ are disjoint closed sets in some metric space $X$, prove that they are separated.
	\item Prove the same for disjoint open sets.
	\item Fix $p\in X$, $\delta > 0$, define $A$ to be the set of all $q\in X$ for which $d\left(p,q\right)<\delta$, define $B$ similarly, with $>$ in place of $<$. Prove that $A$ and $B$ are separated.
	\item Prove that every connected metric space with at least two points is uncountable. \textit{Hint}: Use (c).
\end{enumerate}
\end{problem}

\begin{proof}
{\color{red}Recall that two sets $A$ and $B$ are separated if both $A\cap \overline{B}$ and $\overline{A}\cap B$ are empty.}
\begin{enumerate}[label=(\alph*)]
	\item Let $A$ and $B$ be disjoint and closed. By definition of closed, $A$ contains all of its limit points and $B$ contains all of its limit points. Thus, $A=\overline{A}$ and $B=\overline{B}$. Since $A$ and $B$ are disjoint, we have $A\cap \overline{B} = A\cap B = \varnothing$ and $\overline{A}\cap B = A\cap B = \varnothing$. That is, disjoint closed sets in a metric space are separated.
	\item {\color{red}For disjoint open sets, we cannot use the same trick with the limit points, since open sets do not necessarily contain their limit points.} Assume by way of contradiction that $B$ contains some limit point of $A$, say $x$. Then since $B$ open, there is some open neighborhood $U_x$ of $x$ with $U_x \subset B$. But since $x$ is a limit point of $A$, the neighborhood $U_x$ contains some point $y$ of $A$. But then we have $y \in U_x \subset B$, and $A$ and $B$ are assumed to be disjoint $\bot$. Thus, neither $A$ nor $B$ may contain a limit point of the other, and so $A$ and $B$ are separated.
	\item Let $A= \left\{ q\in X\, | \, d\left(p,q\right) < \delta \right\}${\color{red}; this is an open ball about $p$ in the $d$ metric, and it is certainly open (in that metric)}. Similarly, $B$ is the open complement of $A$, and is easily also open. Then $A$ and $B$ are disjoint open sets in metric space $X$, and so by (b) the two are separated.
	\item Let $X$ be a connected metric space containing two distinct points $x$ and $y$. Let $\delta = \frac{1}{2}d\left(x,y\right)$ and define $A$ and $B$ as in (c) but with this $\delta >0$. Then $A$ and $B$ separate $X$ unless there is some $z$ with $d\left(x,z\right) = \delta$. Since $X$ connected, this $z$ must exist. We picked $\delta = d\left(x,y\right)/2$ arbitrarily; we might just as easily have chosen $0<\delta <d\left(x,y\right)$ and for each choice of $\delta$ we obtain some $z\in X$. Thus, we have a bijection from $\left(0,d\left(x,y\right)\right)$ to a subset of $X$ (the $z$), and so this subset is uncountable. Thus, $X$ itself must be uncountable.
\end{enumerate}
\end{proof}



\begin{problem}{2.20}
Are closures and interiors of connected sets always connected? (Look at subsets of $\mathbb{R}^2$.)
\end{problem}
\begin{proof}

\end{proof}





\begin{problem}{2.21}
Let $A$ and $B$ be separated subsets of some $\mathbb{R}^k$, suppose $a\in A$, $b \in B$, and define $$ p\left(t\right) = \left(1-t\right)a + tb$$ for $t \in \mathbb{R}^1$. Put $A_0 = p^{-1}\left(A\right)$, $B_0 = p^{-1}\left(B\right)$. Thus $t\in A_0$ if and only if $p\left(t\right) \in A$.
\begin{enumerate}[label=(\alph*)]
	\item Prove that $A_0$ and $B_0$ are separated subsets of $\mathbb{R}^1$. \\
	\item Prove that there exists $t_0 \in \left(0,1\right)$ such that $p\left(t_0\right) \notin A\cup B$. \\
	\item Prove that every convex subset of $\mathbb{R}^k$ is connected.
\end{enumerate}
\end{problem}
\begin{proof}
\begin{enumerate}[label=(\alph*)]
	\item Note that $p$ is a parametrization of the line in $\mathbb{R}^k$ through both $a\in A$ and $b\in B$. The sets $A_0, B_0 \in \mathbb{R}^1$ are the preimage of the sets $A$ and $B$ in $\mathbb{R}^k$, respectively. Assume by way of contradiction that $A_0$ and $B_0$ are not separated, that is, that there is some point $t'$ in either $A_0 \cap \overline{B_0}$ or $\overline{A_0}\cap B_0$. Without loss of generality, take $t' \in A_0 \cap \overline{B_0}$. Then $p\left(t'\right) \in A$, and $t'$ is a limit point of $B_0$.  The trick is to show that $p\left(t'\right)$ is a limit point of $B$.
	
	Let $V\subset \mathbb{R}^k$ be an arbitrary open neighborhood of $p\left(t'\right)$. Then we have some open ball about $p\left(t'\right)$ and within $V$. This ball must be intersected by the line parametrized as $p\left(t\right)$; that is, there is some $p\left(t\right)$ within this 
\end{enumerate}
\end{proof}





\begin{problem}{2.22}
A metric space is called \textit{separable} if it contains a countable dense subset. Show that $\mathbb{R}^k$ is separable. \textit{Hint}: Consider the set of points which have only rational coordinates.
\end{problem}
\begin{proof}
We know that $\mathbb{R}^1$ is separable: the rationals $\mathbb{Q}$ are a countable dense subset. We want to generalize this to $\mathbb{R}^k$. Note by Theorem 2.13 that the set of all $k$-tuples of rational numbers are rational. (There is an obvious bijection between $k$-tuples and points in $\mathbb{R}^k$.) Thus, the subset of $\mathbb{R}^k$ of points with rational coordinates, written $\mathbb{Q}^k$, is countable.

It remains to show that this set $\mathbb{Q}^k$ is dense in $\mathbb{R}^k$, i.e., that $\overline{\mathbb{Q}^k} = \mathbb{R}^k$. We expect that this will be inherited from the case where $k=1$. Let $V$ be an arbitrary open set containing the point $x \in \mathbb{R}^k$; we must show that $V$ contains a point of $\mathbb{Q}^k$. Since $V$ open, there is some open ball neighborhood $B_r\left(x\right) \subset V$ of $x$. Note that, for each $i=1,\ldots,k$, we have some rational number $y^i$ so that $$ x^i - r/\sqrt{k} < y^i < x^i + r/\sqrt{k} $$ thanks to the denseness of the rationals in the reals. Then we have $$ \left| x^i - y^i \right| < \frac{r}{\sqrt{k}}. $$ With this in hand, we have $$ \left|y-x\right|^2 = \sum_{i=1}^k \left|y^i - x^i\right|^2 < \sum_{i=1}^k \left(\frac{r}{\sqrt{k}}\right)^2 = r^2 $$ so that $y \in B_r\left(x\right) \subset V$ and $y \in \mathbb{Q}^k$. Thus, we have a point of $\mathbb{Q}^k$ distinct from $x$ in every open set $V$ about $x$; in other worse, $\mathbb{Q}^k$ is dense in $\mathbb{R}^k$.

Together, we have shown that $\mathbb{Q}^k$ is a countable, dense subset of $\mathbb{R}^k$, and so $\mathbb{R}^k$ is separable.
\end{proof}




\begin{problem}{2.23}
A collection $\left\{V_{\alpha}\right\}$ of open subsets of $X$ is said to be a \textit{base} for $X$ if the following is true: For every $x\in X$ and every open set $G \subset X$ such that $x \in G$, we have $x \in V_{\alpha} \subset G$ for some $\alpha$. In other words, every open set in $X$ is the union of a subcollection of $\left\{V_{\alpha}\right\}$.

Prove that every separable metric space has a \textit{countable} base. \textit{Hint}: Take all neighborhoods with rational radius and center in some countable dense subset of $X$.
\end{problem}
{\color{red}The hint really gives away the difficult part of the proof. The existence of a countable base (AKA basis) is referred to by saying that $X$ is second-countable, or that it is a completely separable space. In this case, the countable stuff is provided by the separability assumption. Also notice that though this is an abstract metric space, the rationals (and reals) come in by way of the metric. Thus, we are able to make use to things like ``rational radii.''}\\

\begin{proof}
	Let $\left(X,d\right)$ be a metric space which is separable, and denote the countable dense subset by $K = \left\{x_1,x_2,\ldots\right\}$. Then about each $x_j \in K$ we have a countable set of ball neighborhoods $B_r\left(x_j\right)$ where $r\in \mathbb{Q}$, since $\mathbb{Q}$ is countable. It remains to show that this collection $$ \mathcal{B} = \left\{ B_r\left(x_j\right) \, : \, x_j \in K, r\in \mathbb{Q}\right\}$$ is actually a base for the metric space $X$.
	
	Let $G\subset X$ be open and let $x\in G$. We want to show that $x \in B_r\left(x_j\right)\subset G$ for some $B_r\left(x_j\right) \in \mathcal{B}$. Since $G$ is open, there is a ball neighborhood of $x$, $B_{\delta}\left(x\right) \subset G$, $\delta > 0$. Since the set $K$ is dense in $X$, we have some element $x_j \in B_{\delta/n}\left(x\right)$ for any $n>2$ (pick one). That is, $$ d\left(x,x_j\right) < \frac{\delta}{n}. $$ 
	
	We want to show that $B_{\delta/n}\left(x_j\right) \subset B_{\delta}\left(x\right)$. Let $y \in B_{\delta/n} \left(x_j\right)$. Then
	\begin{align*}
		d\left(y,x\right) & \leq d\left(y,x_j\right) + d\left(x_j,x\right) \\
		& < \frac{\delta}{n} + \frac{\delta}{n} \\
		& < \frac{2}{n}\delta \\
		& < \delta
	\end{align*}
	since we chose $n>2$. Thus, we have the ball inclusion $B_{\delta/n}\left(x_j\right) \subset B_{\delta}\left(x\right) \subset G$.
	
	We are nearly done. Note that the ball $B_{\delta/n}\left(x_j\right)$ is not necessarily in our proposed base since $\delta/n \notin \mathbb{Q}$, in general. By the denseness of the rationals in the reals, we can find some rational $r$ with $$d\left(x,x_j\right)<r<\delta/n.$$ Then $B_r\left(x_j\right) \subset B_{\delta/n}\left(x_j\right) \subset B_{\delta}\left(x\right) \subset G$, and clearly $B_r\left(x_j\right) \in \mathcal{B}$. Hence, this is a countable base for $\left(X,d\right)$.
\end{proof}





\begin{problem}{2.25}
Prove that every compact metric space $K$ has a countable base, and that $K$ is therefore separable. \textit{Hint}: For every positive integer $n$, there are finitely many neighborhoods of radius $1/n$ whose union covers $K$.
\end{problem}
\begin{proof}
Let $K$ be a compact metric space. As the hint suggests, for each $n\in \mathbb{N}$ we have an open cover of $K$ by the collection $$\mathcal{B}^n = \left\{ B_{1/n}\left(x\right)\, : \, x\in K \right\}.$$ Since $K$ is compact, a finite subcollection of each $\mathcal{B}^n$, say $\mathcal{C}^n$, covers $K$: note that this amounts to a finite subset $K^n \subset K$ at which the covering balls are centered. Hence, we have a countable collection of finite open subcovers of $K$, the $\mathcal{C}^n$, the union of which is a cover of $K$. Precisely, we have 
\begin{align*}
	\mathcal{C}^1 & = \left\{  B_{1/1}\left(x^1_j\right) \, : \, x^1_j \in K^1 \right\} \\
	\mathcal{C}^2 & = \left\{  B_{1/2}\left(x^2_j\right) \, : \, x^2_j \in K^2 \right\} \\
	 & \vdots \\
		\mathcal{C}^n & = \left\{  B_{1/n}\left(x^n_j\right) \, : \, x^n_j \in K^n \right\} \\
		 & \vdots  \\
\end{align*}
and each $\mathcal{C}^i$ covers $K$; hence, $$ \mathcal{C} = \cup_{i=1}^{\infty} \mathcal{C}^i$$ covers $K$, and is certainly countable. (Note: without compactness, we would not be able to take the finite subcollections $\mathcal{C}^i$, and there is no guarantee that such a countable subcollection would exist.)

It remains to show that $\mathcal{C}$ is a base for $K$. Let $G\subset K$ be open, and let $x\in G$. Then there is some ball neighborhood $B_r\left(x\right)\subset G$ since $G$ is open. Pick $n\in \mathbb{N}$ so that $0 < \frac{1}{n} < \frac{r}{2}$. Then since $\mathcal{C}^n$ covers $K$, there is some $B_{1/n}\left(x_j^n\right)$ containing $x$. We can show that our judicious choice of this $n$ forces this cover element to lie within $G$ and, specifically, within the ball $B_r\left(x\right)$. Consider $y\in B_{1/n}\left(x_j^n\right)$. Then
\begin{align*}
	\left|y-x\right| & \leq \left|y-x_j^n\right| + \left|x_j^n-x\right| \\
	& < \frac{1}{n} + \frac{1}{n} \\
	& < 2 \cdot \frac{r}{2} \\
	& = r
\end{align*}
so that $y \in B_r\left(x\right)$. Thus, we have shown that $B_{1/n}\left(x_j^n\right)\subset B_r\left(x\right) \subset G$. Hence, $\mathcal{C}$ is a base. We have demonstrated the existence of a countable base for $K$.

That $K$ is separable is easily seen if we take the countable dense subset $X$ to be comprised of an element from within each of these countable basis elements. The set $X$ is then certainly countable, and it is dense since it has an element within every basis element (which necessarily surround every point of $K$).
\end{proof}










\begin{problem}{2.29}
	Prove that every open set in $\mathbb{R}^1$ is the union of an at most countable collection of disjoint segments. \textit{Hint}: Use Exercises 22.
\end{problem}
\begin{proof}
	We know that $\mathbb{R}^1$ is separable since it contains $\mathbb{Q}$ as a countable dense subset. 
\end{proof}





\newpage
\section*{Chapter 3. Numerical Sequences and Series}

\begin{problem}{3.1}
Prove that convergence of $\left\{s_n\right\}$ implies convergence of $\left\{\left|s_n\right|\right\}$. is the converse true?
\end{problem}
\begin{proof}
This is true from the triangle inequality. If $\left\{s_n\right\}$ converges, let $\epsilon>0$ and we have some $N\in \mathbb{N}$ so that $n>N \implies \left| s_n - L\right|<\epsilon$, where $L$ is the limit of the sequence. Then for $n>N$, by the triangle inequality we have $\left|\left|s_n\right|-\left|L\right|\right| \leq \left|s_n-L\right| < \epsilon$ and so $\lim_{n\rightarrow \infty} \left|s_n\right| = \left|L\right|$.

The converse is not true. The sequence $s_n = \left(-1\right)^n$ does not converge, but the sequence $\left|s_n\right|=1$ trivially converges.
\end{proof}


\begin{problem}{3.2}
Calculate $\lim_{n\rightarrow \infty} \left(\sqrt{n^2+n}-n\right)$.
\end{problem}
\begin{proof}
We can guess what this limit might be by considering the function $f\left(x\right) = \sqrt{n^2+n}-n$. We can guess the limit as $x\rightarrow \infty$ by the usual trick of rationalizing the denominator:
\begin{equation*}
\begin{split}
\sqrt{x^2+x}-x & = \left( \sqrt{x^2+x}-x\right)\left( \frac{\sqrt{x^2+x}+x}{\sqrt{x^2+x}+x}\right) \\
& = \frac{x}{\sqrt{x^2+x}+x} \\
& = \frac{1}{1+\sqrt{1+\frac{1}{x} }}
\end{split}
\end{equation*}
where the last equality is allowed since $x$ is away from $0$. Without formally taking limits, we can see that as $x$ gets very large, the $1/x$ term tends toward $0$ and the entire quantity then tends toward $1/2$.
\end{proof}


\begin{problem}{3.3}
If $s_1=\sqrt{2}$, and $$s_{n+1}=\sqrt{2+\sqrt{s_n}} \hspace{10mm} \left(n=1,2,3,\ldots\right), $$ prove that $\left\{s_n\right\}$ converges, and that $s_n < 2$ for $n=1,2,3,\ldots$.
\end{problem}
\begin{proof}

To see that $s_n < 2$ always, we can use induction. First, we certainly have $s_1 = \sqrt{2} < 2$ since $s_1^2 = 2 < 2^2$. Next, assume that $s_n < 2$. Then $$s_{n+1} = \sqrt{2 + \sqrt{s_n}} < \sqrt{2 + \sqrt{2}} < \sqrt{2+2} = 2 .$$ By induction, then, $s_n < 2$ for all $n$. It is clearly a monotonic sequence, and so it converges by the monotonic convergence theorem.
\end{proof}



\begin{problem}{3.4}
Find the upper and lower limits of the sequence $\left\{s_n\right\}$ defined by $$ s_1=0; \hspace{5mm} s_{2m} = \frac{s_{2m-1}}{2}; \hspace{5mm} s_{2m+1} = \frac{1}{2}+s_{2m}.$$
\end{problem}
\begin{proof}
To get some intuition, it helps to write out (or, even better, plot) some points of this sequence: $$ 0, 0, \frac{1}{2}, \frac{1}{4}, \frac{3}{4}, \frac{3}{8}, \frac{7}{8}, \frac{7}{16}, \frac{15}{16}, \frac{15}{32}, \frac{31}{32},\ldots   $$ It looks like the lim sup is $1$ and lim inf is $\frac{1}{2}$. It will be easier to prove this if we can write the sequence in terms of the index $m$, so let's do this. 
\end{proof}




\begin{problem}{3.5}
For any two real sequences $\left\{a_n\right\}$, $\left\{b_n\right\}$, prove that $$ \limsup_{n\rightarrow \infty} \left(a_n + b_n\right) \leq \limsup_{n\rightarrow \infty} a_n + \limsup_{n\rightarrow \infty} b_n, $$ provided the sum on the right is not of the form $\infty - \infty$.
\end{problem}
\begin{proof}
Recall that the $\limsup$ of a sequence is defined as the supremum of the set of all subsequential limits of the sequence. Thus, consider two sequences $\left(a_n\right)$ and $\left(b_n\right)$ which do not have $\limsup$s equal to $\infty$ (if either does, both sides of the inequality are infinity and the conclusion is trivial).

Assume by way of contradiction that we name $$ \alpha = \limsup_{n\rightarrow \infty} \left(a_n+b_n\right),$$ $$ \beta_1 = \limsup_{n\rightarrow \infty} a_n, $$ and $$\beta_2 = \limsup_{n\rightarrow \infty} b_n; $$ assume that we have $\alpha > \beta_1 + \beta_2 $. Let $x\in \mathbb{R}$ so that $\beta_1 + \beta_2 < x < \alpha$. 
\end{proof}





\begin{problem}{3.7}
Prove that the convergence of $\sum a_n$ implies the convergence of $$ \sum \frac{\sqrt{a_n}}{n}, $$ if $a_n \geq 0$.
\end{problem}
\begin{proof}
	Assume $\sum a_n$ converges and that $a_n \geq 0$. Then we know that $a_n \rightarrow 0$.
\end{proof}





\begin{problem}{3.8}
if $\sum a_n$ converges, and if $\left\{b_n\right\}$ is monotonic and bounded, prove that $\sum a_n b_n$ converges.
\end{problem}
\begin{proof}

\end{proof}



\begin{problem}{3.9}
Find the radius of convergence of each of the following power series:
	\begin{enumerate}[label=(\alph*)]
		\item $\sum n^3 z^n $, 
		\item $\sum \frac{2^n}{n!}z^n$,
		\item $\sum \frac{2^n}{n^2}z^n$,
		\item $\sum \frac{n^3}{3^n}z^n$.
	\end{enumerate}
\end{problem}
{\color{red} Note that the ratio test involves lim sups. In these problems, since the sequences easily converge, we know that the limit of the each sequence is the same as the lim sup (and lim inf) of that sequence.}
\begin{proof}
	\begin{enumerate}[label=(\alph*)]
		\item The ratio test applies here: \begin{align*}
			\left| \frac{\left(n+1\right)^3 z^{n+1}}{n^3 z^n} \right| & = \left(1+\frac{1}{n}\right)^3 \left|z\right| \rightarrow \left|z\right| \\
		\end{align*} 
		Thus, by the ratio test, this series converges for $\left|z\right|<1$.
		
		\item The ratio test applies again: \begin{align*}
		\left| \frac{2^{n+1}}{\left(n+1\right)!}\frac{z^{n+1}}{z^n} \frac{n!}{2^n}\right| & = \frac{2}{n+1} \left| z\right| \rightarrow 0 
		\end{align*} and so this series converges for all $z$.
		
		\item Let's try the ratio test again: \begin{align*}
		\left| \frac{2^{n+1}}{\left(n+1\right)^2}\frac{z^{n+1}}{z^n}\frac{n^2}{2^n} \right| & = \frac{2}{\left(1 + 1/n\right)^2} \left|z\right| \rightarrow 2\left|z\right|
		\end{align*} so this series converges for $\left|z\right| < \frac{1}{2}$.
		
		\item Once again:\begin{align*}
		\left| \frac{\left(n+1\right)^3}{3^{n+1}} \frac{z^{n+1}}{z^n} \frac{3^n}{n^3}\right| & = \frac{\left(1+1/n\right)^3}{3}\left|z\right| \rightarrow \frac{1}{3}\left|z\right|
		\end{align*} so the series converges for $\left|z\right|<3$.
	\end{enumerate}
\end{proof}


\begin{problem}{3.20}
Suppose $\left\{p_n\right\}$ is a Cauchy sequence in a metric space $X$, and some subsequence $\left\{p_{n_i}\right\}$ converges to a point $p\in X$. Prove that the full sequence $\left\{p_n\right\}$ converges to $p$.
\end{problem}
{\color{red}Since the sequence is Cauchy, \textit{all} elements must get arbitrarily close together. Since we have a subsequence converging toward a specific point, we must have \textit{all} elements converging toward that point.}\\

\begin{proof}
Let $\left\{p_n\right\}$ be a Cauchy sequence in $X$ with convergent subsequence $p_{n_i}\rightarrow p \in X$. Since the sequence is Cauchy, we have for any $\epsilon>0$ an $N'\in \mathbb{N}$ so that $$ n,m > N' \implies d\left(p_n,p_m\right) < \epsilon/2.$$ By the definition of convergent (sub)sequence, we have an $N''\in \mathbb{N}$ so that $$n_i > N'' \implies d\left(p_{n_i}, p\right)<\epsilon/2.$$ Take $N = \max \left\{N',N''\right\}$; then fix $n_i > N$ and we have, for $n>N$,
\begin{align*}
	d\left(p_n, p\right) & \leq d\left(p_n, p_{n_i}\right) + d\left(p_{n_i}, p\right) \\
	& < \frac{\epsilon}{2} + \frac{\epsilon}{2} \\
	& = \epsilon
\end{align*}
Note that we needed Cauchy-ness of $\left\{p_n\right\}$ in order to bound the term ``$d\left(p_n,p_{n_i}\right)$.''
\end{proof}



\begin{problem}{3.21}
Prove the following analogue of Theorem 3.10(\textit{b}): If $\left\{E_n\right\}$ is a sequence of closed nonempty and bounded sets in a \textit{complete} metric space $X$, if $E_n \supset E_{n+1}$, and if $$\lim_{n\rightarrow \infty} \text{diam} \, E_n = 0,$$ then $\cap_1^{\infty} E_n$ consists of exactly one point.
\end{problem}
{\color{red}The Theorem 3.10(\textit{b}) is the same statement but for a sequence of compact sets in an arbitrary --- not necessarily complete --- metric space. In this exercise, we want to show that it holds for closed and bounded subsets when the space is complete; somehow, completeness is required to make this hold. This helps to illuminate the differences between closed-and-bounded and compact sets in an arbitrary metric space (in Euclidean spaces they are the same by the Heine-Borel theorem).}\\

\begin{proof}
We first show that the intersection $E = \cap_1^{\infty} E_n$ cannot be empty. Note that since each $E_n$ is nonempty, we have some element $x_n \in E_n$ for every $n\in \mathbb{N}$. We want to show that this sequence is Cauchy. Let $\epsilon>0$. Then since $\lim_n \text{diam} \, E_n=0$, we have some $N\in \mathbb{N}$ so that $n>N \implies \text{diam} \, E_n<\epsilon$. Note that by construction of the sequence $\left\{ x_n\right\}$, we have $n>N \implies x_n \in E_{N+1}$. Thus, if $n,m > N$, we have $x_n, x_m \in E_{N+1}$, and so $d\left(x_n,x_m\right) \leq \text{diam}\, E_{N+1} < \epsilon$. We have shown that the sequence $\left\{x_n\right\}$ is Cauchy. Since $X$ is complete, this sequence converges in $X$. Since each sequence set $E_n$ is closed, this limiting point is in the intersection, and so the intersection is nonempty.

Next, we assume that there are at least two points in $E$. For the same reasons as in the proof of Theorem 3.10(\textit{b}), this raises a contradiction: with two distinct points, $\text{diam}\, E > 0$, but $E \subset E_n$ and so $\text{diam}\, E \leq \text{diam}\, E_n$. But we assumed $\text{diam}\, E_n \rightarrow 0$.
\end{proof}




\begin{problem}{3.22}
Suppose $X$ is a nonempty complete metric space, and $\left\{G_n\right\}$ is a sequence of dense open subsets of $X$. Prove Baire's theorem, namely, that $\cap_1^{\infty} G_n$ is not empty. (In fact, it is dense in $X$.) \textit{Hint}: Find a shrinking sequence of neighborhoods $E_n$ such that $\overline{E_n}\subset G_n$, and apply Exercise 21.
\end{problem}
{\color{red}A topological space is called a \textbf{Baire space} if the intersection of every countable collection of open dense subsets is itself dense.}\\

\begin{proof}
By the previous problem, we know that a sequence of closed, nonempty, and bounded  sets with diameters limiting to $0$ have a nonempty intersection.
\end{proof}




\begin{problem}{3.23}
Suppose $\left\{p_n\right\}$ and $\left\{q_n\right\}$ are Cauchy sequences in a metric space $X$. Show that the sequence $\left\{d\left(p_n,q_n\right)\right\}$ converges. \textit{Hint}: for any $m,n$, $$ d\left(p_n,q_n\right) \leq d\left(p_n,p_m\right) + d\left(p_m,q_m\right) + d\left(q_m,q_n\right);$$ it follows that $$ \left| d\left(p_n,q_n\right) - d\left(p_m,q_m\right)\right|$$ is small if $m$ and $n$ are large.
\end{problem}
\begin{proof}
The hint really gives away the main difficulty of the problem. Consider the Cauchy sequences $\left\{p_n\right\}$ and $\left\{q_n\right\}$. Then we can prove the hint: let $\epsilon>0$ be given, and let $M,N\in \mathbb{N}$ so that $$ n,m>N \implies d\left(p_n,p_m\right) < \epsilon/2 $$ and $$ n,m>M \implies d\left(q_n,q_m\right) < \epsilon/2 $$ (these exist since the sequences are Cauchy). By the triangle inequality, we have for any $n,m\in \mathbb{N}$ $$ d\left(p_n,q_n\right) \leq d\left(p_n,p_m\right) + d\left(p_m, q_m\right) + d\left(q_m,q_n\right) $$ so that $$ \left| d\left(p_n,q_n\right)-d\left(p_m, q_m\right) \right| \leq d\left(p_n,p_m\right) + d\left(q_m,q_n\right).$$ Then if we take $n,m > \max \left\{N,M\right\}$, we have \begin{align*}
\left|d\left(p_n,q_n\right) - d\left(p_m,q_m\right) \right| & \leq d\left(p_n,p_m\right) + d\left(q_m,q_n\right) \\
& < \epsilon/2  + \epsilon/2 \\
& = \epsilon\\
\end{align*} 
We have shown that the sequence $\left\{d\left(p_n,q_n\right)\right\}$ is a Cauchy sequence. Moreover, it is a Cauchy sequence in $\mathbb{R}^1$, which is a complete metric space, and so it converges.
\end{proof}



\begin{problem}{3.24}
Let $X$ be a metric space.
\begin{enumerate}[label=(\alph*)]
	\item Call two Cauchy sequences $\left\{p_n\right\}, \left\{q_n\right\}$ in $X$ \textit{equivalent} if $$ \lim_{n\rightarrow \infty} d\left(p_n,q_n\right)=0.$$ Prove that this is an equivalence relation.
	\item Let $X^*$ be the set of all equivalence classes so obtained. If $P\in X^*$, $Q\in X^*$, $\left\{p_n\right\}\in P, \left\{q_n\right\}\in Q$, define $$ \Delta \left(P,Q\right) = \lim_{n\rightarrow \infty} d\left(p_n,q_n\right);$$ by Exercise 23, this limit exists. Show that the number $\Delta \left(P,Q\right)$ is unchanged if $\left\{p_n\right\}$ and $\left\{q_n\right\}$ are replaced by equivalent sequences, and hence that $\Delta$ is a distance function in $X^*$.
	\item Prove that the resulting metric space $X^*$ is complete.
	\item For each $p\in X$, there is a Cauchy sequence all of whose terms are $p$; let $P_p$ be the element of $X^*$ which contains this sequence. Prove that $$ \Delta\left(P_p,P_q\right) = d\left(p,q\right)$$ for all $p,q\in X$. In other words, the mapping $\varphi$ defined by $\varphi\left(p\right) = P_p$ is an isometry (i.e., a distance-preserving mapping) of $X$ into $X^*$.
	\item Prove that $\varphi\left(X\right)$ is dense in $X^*$, and that $\varphi\left(X\right)=X^*$ is $X$ is complete. By (\textit{d}), we may identify $X$ and $\varphi\left(X\right)$ and thus regard $X$ as embedded in the complete metric space $X^*$. We call $X^*$ the \textit{completion} of $X$.
\end{enumerate}
\end{problem}

\begin{proof}
\begin{enumerate}[label=(\alph*)]
	\item It is fairly easy to see that this is an equivalence relation. That it is reflexive and symmetric follows from the definition of metric: $$ \lim_{n\rightarrow \infty} d\left(p_n,p_n\right) = \lim_{n\rightarrow \infty} 0 = 0 $$ and $$ 0 = \lim_{n\rightarrow \infty} d\left(p_n,q_n\right) = \lim_{n\rightarrow \infty} d\left(q_n,p_n\right),$$ the second by symmetry of the metric. Lastly, let $\left\{ p_n \right\}$ be equivalent to $\left\{ q_n\right\}$ and let $\left\{q_n \right\}$ be equivalent to $\left\{ s_n\right\}$. Then by the triangle inequality we have $$ d\left(p_n,s_n\right) \leq d\left(p_n,q_n\right) + d\left(q_n,s_n\right). $$ The right-hand side tends to $0$ as $n\rightarrow \infty$, and thus so does the left-hand side. Hence, Cauchy sequence equivalence is an equivalence relation.
	
	\item Assume $P,Q\in X^*$ are two equivalence classes with representative elements $\left\{p_n\right\}, \left\{q_n\right\}$, respectively. Let $\Delta = \lim_{n\rightarrow \infty} d\left(p_n,q_n\right)$; the goal is to show that $\Delta$ is well-defined as a function on the equivalence classes. Let $\left\{p_n'\right\}$ and $\left\{q_n'\right\}$ be any two other representative sequences of $P$ and $Q$, respectively. Then
	\begin{align*}
		d\left(p_n',q_n'\right) & \leq d\left(p_n',q_n\right) + d\left(q_n,q_n'\right)  \\
		& \leq d\left(p_n',p_n\right) + d\left(p_n,q_n\right) +  d\left(q_n,q_n'\right) 
	\end{align*}
	by two successive applications of the triangle inequality. We take the limit of both sides as $n\rightarrow \infty$ to obtain $$ \lim_{n\rightarrow \infty} d\left(p_n',q_n'\right) \leq  \lim_{n\rightarrow \infty} d\left(p_n,q_n\right) = \Delta. $$ Conversely, we can similarly apply the triangle inequality again: 
	\begin{align*}
		d\left(p_n,q_n\right) & \leq d\left(p_n,q_n'\right) + d\left(q_n',q_n\right)  \\
		& \leq d\left(p_n,p_n'\right) + d\left(p_n',q_n'\right) +  d\left(q_n',q_n\right) 
	\end{align*}
	and after taking limits we obtain
	$$ \Delta \leq \lim_{n\rightarrow \infty} d\left(p_n',q_n'\right). $$ Taken together, we have shown that $\lim_{n\rightarrow \infty} d\left(p_n',q_n'\right) = \Delta$, so that we can uniquely define the metric $\Delta$ on the equivalence classes.
	
	\item To show that this metric space is complete, we must show that all Cauchy sequences converge. Let $\left\{P_n\right\}$ be a Cauchy sequence in $X^*$ (it is a sequence of equivalence classes). Presumably it will inherit its Cauchy-ness from the Cauchy-ness of its representative elements in $X$.
	
\end{enumerate}
\end{proof}















\newpage
\section*{Chapter 4. Continuity}

\begin{problem}{4.1}
Suppose $f$ is a real function defined on $\mathbb{R}^1$ which satisfies $$ \lim_{h\rightarrow 0} \left[f\left(x+h\right)-f\left(x-h\right)\right] = 0 $$ for every $x\in \mathbb{R}^1$. Does this imply that $f$ is continuous?
\end{problem}
\begin{proof}
What the condition is showing is that $f$ approaches the same value from the right as it does from the left: it says nothing about what the function value actually \textit{is} at $x$. Thus, a counterexample is a function with a point discontinuity: let $$ f\left(x\right) = \left\{ \begin{array}{rl} 0, & x \neq 0 \\ 1, & x=0 \end{array} \right. $$ Then clearly $$ \lim_{h\rightarrow 0} \left[f\left(x+h\right)-f\left(x-h\right)\right] = \lim_{h\rightarrow 0} 0 = 0 $$ but $f\left(0\right) = 1$, hence $f$ is not continuous at $x=0$.
\end{proof}

\begin{problem}{4.2}
If $f$ is a continuous mapping of a metric space $X$ into a metric space $Y$, prove that $$ f\left(\overline{E}\right) \subset \overline{f\left(E\right)} $$ for every set $E\subset X$. ($\overline{E}$ denotes the closure of $E$.) Show, by an example, that $f\left(\overline{E}\right)$ can be a proper subset of $\overline{f\left(E\right)}$.
\end{problem}
\begin{proof}
Let $f:X\rightarrow Y$ on metric spaces $X$ and $Y$. Let $E\subset X$ and consider some $y\in f\left(\overline{E}\right)$ and an arbitrary open set $V$ about $y$. Then we have some (at least one) $x\in \overline{E}$ so that $f\left(x\right) =y$. If $x\in E$, then we are done: $y=f\left(x\right) \in f\left(E\right) \subset \overline{f\left(E\right)}$. On the other hand, assume $x$ is a limit point of $E$. By continuity of $f$, $f^{-1}\left(V\right)$ is an open set containing $x$. Then there is some $x' \in f^{-1}\left(V\right)\cap E$, since $x$ is a limit point of $E$. Then, of course, $f\left(x'\right) \in f\left(f^{-1}\left(V\right)\cap E\right) = V\cap f\left(E\right)$ so that the arbitrary open neighborhood $V$ of $y$ contains a point of $f\left(E\right)$; hence, $y \in \overline{f\left(E\right)}$, and the theorem is proven.

It seems to be becoming a pattern that counterexamples often involve infinity, since non-intuitive things happen there. Since our function must be continuous, I thought to look at function which has an asymptote. Take $$ f\left(x\right) = \frac{x}{1+x}, \; x\in\left(0,\infty\right) \subset \mathbb{R}. $$ Then certainly $E=\left(0,\infty\right)$ and $\overline{E}=\left[0,\infty\right)$, and $f\left(\overline{E}\right)=\left[0,1\right)$, but $\overline{f\left(E\right)} = \overline{\left(0,1\right)}=\left[0,1\right].$
\end{proof}



\begin{problem}{4.3}
Let $f$ be a continuous real function on a metric space $X$. Let $Z\left(f\right)$ (the zero set of $f$) be the set of all $p\in X$ at which $f\left(p\right)=0$. Prove that $Z\left(f\right)$ is closed.
\end{problem}
{\color{red} Note that this is a very topological proof, and we didn't even need to invoke the $\epsilon$-$\delta$ definitions in these metric spaces. An alternate approach would be to take $p\notin Z\left(f\right)$ and show that it has a neighborhood entirely disjoint from $Z\left(f\right)$, i.e., $Z\left(f\right)$ has an open complement.}\\
\begin{proof}
We will show that $Z\left(f\right)$ contains all of its limit points, and is thus closed. Let $p\in X$ be a limit point of $Z\left(f\right)$. Assume by way of contradiction that $p \notin Z\left(f\right)$, so that $f\left(p\right) \neq 0$. Assume that $f\left(p\right)>0$. Then since $\mathbb{R}$ is a metric space (and Hausdorff), we have open balls $U$ and $V$ about $0$ and $f\left(p\right)$, respectively, so that $U\cap V = \emptyset$. Then $f^{-1}\left(U\right)$ and $f^{-1}\left(V\right)$ are open by continuity of $f$, and $Z\left(f\right)\subset f^{-1}\left(U\right)$ and $p \in f^{-1}\left(V\right)$, and the two preimages clearly do not intersect. Hence, we have a neighborhood of $p$ which contains no points of $Z\left(f\right)$, thus $p$ cannot be a limit point; this is our contradiction. Thus, $Z\left(f\right)$ must contain its limit points, and is closed.
\end{proof}

{\color{red}After reading through the book again, I noticed that the concept of ``Hausdorff'' spaces is not introduced by this point (if at all). I will redo this proof below with just the concepts in the chapter.}\\
\begin{proof}
Let $f:X\rightarrow \mathbb{R}$ be a continuous function on metric space $X$. Let $p$ be a limit point of $Z\left(f\right)$. Since this is a metric space, we can construct the open balls $B\left(p,1/n\right)$ for every $n\in \mathbb{N}$. Then since $p$ is a limit point, we have some point $x_n \in B\left(p,1/n\right)\cap Z\left(f\right)$ for every $n$. This is a sequence which certainly converges to $p$, and we have $f\left(x_n\right)=0$ for all $x_n$ in the sequence. The function $f$ being continuous (at $p$, in particular) means that $\lim_{x\rightarrow p} f\left(x\right) = f\left(p\right)$. Thus, by Theorem 4.2 we have that $\lim_{n\rightarrow \infty} f\left(x_n\right) = f\left(p\right)$ and so $f\left(p\right)=0$, i.e., $p\in Z\left(f\right)$. Thus, $Z\left(f\right)$ contains its limit points and so is closed.
\end{proof}



\begin{problem}{4.4}
Let $f$ and $g$ be continuous mappings of a metric space $X$ into a metric space $Y$, and let $E$ be a dense subset of $X$. Prove that $f\left(E\right)$ is dense in $f\left(X\right)$. If $g\left(p\right)=f\left(p\right)$ for all $p\in E$, prove that $g\left(p\right)=f\left(p\right)$ for all $p\in X$. (In other words, a continuous mapping is determined by its values on a dense subset of its domain.)
\end{problem}
\begin{proof}
Recall that the definition of $E$ being dense in $X$ is that $\overline{E}=X$. Thus, we want to show that $\overline{f\left(E\right)} = f\left(X\right)$. This was already proven in Exercise 4.2: $f\left(X\right) = f\left(\overline{E}\right) \subseteq \overline{f\left(E\right)}$. Thus, any neighborhood of every point of $f\left(X\right)$ contains a point of $f\left(E\right)$, and so $f\left(E\right)$ is dense in $f\left(X\right)$.

To prove the last assertion, define $h := g-f$, certainly continuous (we can show this by the $\epsilon-\delta$ definition) and consider $Z\left(h\right)$. In this formulation, we want to show that $Z\left(h\right) = X$. By our assumption, $E\subset Z\left(h\right)$ and so $Z\left(h\right)$ is also dense in $X$, so $\overline{Z\left(h\right)}=X$. We also know from Exercise 4.3 that $Z\left(h\right)$ is closed, i.e., that $\overline{Z\left(h\right)} = Z\left(h\right)$. Taken together, we have $Z\left(h\right)=\overline{Z\left(h\right)} = X$, and we are done.
\end{proof}



\begin{problem}{4.5}
If $f$ is a real continuous function defined on a closed set $E\subset \mathbb{R}^1$, prove that there exist continuous real functions $g$ on $\mathbb{R}^1$ such that $g\left(x\right)=f\left(x\right)$ for all $x\in E$. (Such functions $g$ are called \textit{continuous extensions} of $f$ from $E$ to $\mathbb{R}^1$.) Show that the result becomes false if the word ``closed'' is omitted. Extend the result to vector-valued functions. \textit{Hint}: Let the graph of $g$ be a straight line on each of the segments which constitute the complement of $E$ (compare Exercise 29, Chap. 2). The result remains true if $\mathbb{R}^1$ is replaced by any metric space, but the proof is not so simple.
\end{problem}
\begin{proof}

\end{proof}











\begin{problem}{4.6}
If $f$ is defined on $E$, the graph of $f$ is the set of points $\left(x,f\left(x\right)\right)$, for $x\in E$. In particular, if $E$ is a set of real numbers, and $f$ is real-valued, the graph of $f$ is a subset of the plane.

Suppose $E$ is compact, and prove that $f$ is continuous on $E$ if and only if its graph is compact.
\end{problem}
\begin{proof}
First, assume $f$ continuous. Then let $$\varphi: E\subset \mathbb{R}^1 \rightarrow \mathbb{R}^1 \times \mathbb{R}^1 $$ be the function mapping $E$ to its graph, $\varphi\left(x\right)=\left(x,f\left(x\right)\right)$. Then by Theorem 4.10, $\varphi$ is continuous if and only if the component functions of $\varphi$ are. These component functions are the identity map and $f$, both of which are continuous, hence $\varphi$ is continuous. Thus, the graph is a continuous image of the compact set $E$, and so is itself compact by Theorem 4.14.

Conversely, assume that the graph of $f$ is compact but that $f$ is not continuous at some point $p\in E$. That is, we have some sequence of points $p_n \rightarrow p$ but $\lim_{n\rightarrow \infty} f\left(p_n\right) \neq f\left(p\right)$. However, since the graph is compact, there is some convergent subsequence, say $\left(p_{n_k}, f\left(p_{n_k}\right)\right)\rightarrow \left(p', f'\right)$ where $f' \neq f\left(p\right)$. Since $\left\{p_n\right\}$ converges to $p$ and $\left\{p_{n_k}\right\}$ is a subsequence, we must have $p'=p$. But then we have $f'=f\left(p\right)$ since $\left(p',f'\right)$ is in the graph of $f$. This shows that the convergent subsequence actually converges to the expected value of the graph at $p$. But we assumed $f$ was not continuous, and so this is not possible. Hence we have a contradiction, and so $f$ must be continuous.
\end{proof}





\begin{problem}{4.8}
	Let $f$ be a real uniformly continuous function on the bounded set $E$ in $\mathbb{R}^1$. Prove that $f$ is bounded on $E$. Show that the conclusion is false if boundedness of $E$ is omitted from the hypothesis.
\end{problem}
\begin{proof}
	Let $f$ be as specified in the hypotheses. (If $f$ were defined on $\overline{E}$, we could apply the (Weierstrass) extreme value theorem to claim that $f$ attains its maximum and minimum values on $\overline{E}$, and we would be done.) 
	
	An easy counterexample if we remove boundedness of $E$ is the identity function $f\left(x\right)=x$ on $E=\left[0,\infty\right)$. It is almost trivially uniformly continuous, but is unbounded as we move toward $\infty$.
\end{proof}













% --------------------------------------------------------------
%     You don't have to mess with anything below this line.
% --------------------------------------------------------------

\end{document}
